# Diagrama del Pipeline ETL - Cliente HTTP Automatizado

## Flujo completo del pipeline:

```mermaid
graph TD
    A["ğŸŒ IngestiÃ³n HTTP<br/>01_ingestion_http<br/>httpbin.org"] 
    B["ğŸ“‹ SimulaciÃ³n de Logs<br/>02_simulation_logs<br/>generar_datos.py"]
    C["ğŸ“Š Procesamiento KPIs<br/>03_kpi_processing<br/>calcular_kpis.py"]
    D["ğŸ”„ ETL - Pentaho<br/>04_etl_pentaho"]
    E["ğŸ“ˆ Reportes<br/>05_reporting<br/>generar_reporte.py"]
    
    F["ğŸ’¾ JSONL<br/>http_logs.jsonl"]
    G["ğŸ“‘ CSV<br/>kpi_por_endpoint_dia.csv"]
    H["ğŸ—„ï¸ SQLite<br/>stg_kpi_endpoint_dia<br/>fct_kpi_endpoint_dia"]
    I["ğŸŒ HTML<br/>kpi_diario.html"]
    
    A -->|Simula| B
    B -->|Genera| F
    F -->|Lee| C
    C -->|Calcula| G
    G -->|Entrada CSV| D
    D -->|Carga| H
    G -->|Visualiza| E
    E -->|Genera| I
    H -->|Fuente| E
    
    style A fill:#e1f5ff
    style B fill:#f3e5f5
    style C fill:#e8f5e9
    style D fill:#fff3e0
    style E fill:#fce4ec
    style F fill:#f5f5f5
    style G fill:#f5f5f5
    style H fill:#f5f5f5
    style I fill:#f5f5f5
```

## Detalle del flujo ETL (MÃ³dulo 04):

```mermaid
graph LR
    CSV["ğŸ“‘ CSV Input<br/>kpi_por_endpoint_dia.csv"]
    
    STEP1["Step 1:<br/>CSV Reader"]
    STEP2["Step 2:<br/>Type Cast"]
    STEP3["Step 3:<br/>Filter Rows<br/>validation"]
    STEP4["Step 4:<br/>Table Output<br/>STG"]
    STEP5["Step 5:<br/>Table Output<br/>FACT"]
    STEP6["Step 6:<br/>Audit Log"]
    
    DB["ğŸ—„ï¸ SQLite<br/>three tables"]
    
    CSV --> STEP1
    STEP1 --> STEP2
    STEP2 --> STEP3
    STEP3 --> STEP4
    STEP4 --> STEP5
    STEP5 --> STEP6
    STEP4 --> DB
    STEP5 --> DB
    STEP6 --> DB
    
    style CSV fill:#fff9c4
    style STEP1 fill:#bbdefb
    style STEP2 fill:#c8e6c9
    style STEP3 fill:#ffccbc
    style STEP4 fill:#f8bbd0
    style STEP5 fill:#f8bbd0
    style STEP6 fill:#d1c4e9
    style DB fill:#ffe0b2
```

## Estructura de datos - Tablas SQLite:

```
STG_KPI_ENDPOINT_DIA (Staging)
â”œâ”€ date_utc (TEXT) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”œâ”€ endpoint_base (TEXT) â”€â”€â”€â”€â”€â”€â”€â”¤â”€ PRIMARY KEY
â”œâ”€ requests_total (INTEGER)    â”‚
â”œâ”€ success_2xx (INTEGER)       â”‚
â”œâ”€ client_4xx (INTEGER)        â”‚
â”œâ”€ server_5xx (INTEGER)        â”‚
â”œâ”€ parse_errors (INTEGER)      â”‚
â”œâ”€ avg_elapsed_ms (REAL)       â”‚
â”œâ”€ p90_elapsed_ms (REAL)       â”‚
â””â”€ created_at (TIMESTAMP)      â””â”€ AuditorÃ­a

FCT_KPI_ENDPOINT_DIA (Fact Table)
â””â”€ [IDÃ‰NTICA A STG]
   (Copia para anÃ¡lisis independiente)

AUDIT_ETL_LOG (AuditorÃ­a)
â”œâ”€ id (INTEGER) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”œâ”€ job_name (TEXT)                â”‚â”€ PRIMARY KEY
â”œâ”€ execution_date (TIMESTAMP)      â”‚
â”œâ”€ records_loaded (INTEGER)        â”‚
â”œâ”€ records_expected (INTEGER)      â”‚
â”œâ”€ status (TEXT)                   â”‚
â”œâ”€ error_message (TEXT)            â”‚
â””â”€ duration_seconds (REAL)         â””â”€ AuditorÃ­a
```

## Job Pentaho (j_daily_kpi.kjb):

```mermaid
graph TD
    START["â–¶ INICIO<br/>j_daily_kpi"]
    TRANS["âš™ Ejecutar Transformation<br/>t_load_kpi.ktr"]
    VALIDATE["âœ“ Validar Registros<br/>success_2xx + client_4xx<br/>+ server_5xx = requests_total"]
    VERIFY["ğŸ” Table Exists Check<br/>Verificar que tablas<br/>existan en BD"]
    LOG["ğŸ“ Write Log<br/>audit_etl_log"]
    SUCCESS["âœ… FIN EXITOSO"]
    FAIL["âŒ ERROR"]
    
    START --> TRANS
    TRANS --> VALIDATE
    VALIDATE -->|OK| VERIFY
    VALIDATE -->|FAIL| LOG
    LOG --> FAIL
    VERIFY -->|OK| LOG
    VERIFY -->|FAIL| LOG
    LOG -->|Success| SUCCESS
    LOG -->|Fail| FAIL
    
    style START fill:#c8e6c9
    style TRANS fill:#bbdefb
    style VALIDATE fill:#ffccbc
    style VERIFY fill:#f8bbd0
    style LOG fill:#d1c4e9
    style SUCCESS fill:#a5d6a7
    style FAIL fill:#ef9a9a
```

## Pipeline completo - Vista macro:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CLIENTE HTTP AUTOMATIZADO                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  01 - IngestiÃ³n  â”‚   â”‚  02 - SimulaciÃ³n â”‚   â”‚  03 - CÃ¡lculo    â”‚
â”‚      HTTP        â”‚â”€â”€â†’â”‚      de Logs     â”‚â”€â”€â†’â”‚      de KPIs      â”‚
â”‚ httpbin.org      â”‚   â”‚ generar_datos.py â”‚   â”‚ calcular_kpis.py â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚                            â”‚                            â”‚
                          â–¼                            â–¼                            â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  04 - ETL        â”‚       â”‚  05 - Reportes   â”‚       â”‚  AnÃ¡lisis Local  â”‚
                   â”‚    Pentaho       â”‚       â”‚     HTML         â”‚       â”‚     CSV / XML    â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚    SQLite DB     â”‚
                   â”‚  - stg_*         â”‚
                   â”‚  - fct_*         â”‚
                   â”‚  - audit_*       â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Componentes del Job ETL:

1. **CSV Input**: Lee `kpi_por_endpoint_dia.csv`
2. **Type Casting**: Convierte strings a tipos correctos (fecha, int, float)
3. **Filter Rows**: Valida que parse_errors + 2xx + 4xx + 5xx = requests_total
4. **Table Output (STG)**: Inserta en stg_kpi_endpoint_dia
5. **Table Output (FCT)**: Inserta en fct_kpi_endpoint_dia
6. **Audit Logger**: Registra resultado en audit_etl_log

## Validaciones del Job:

- âœ“ Archivo CSV existe
- âœ“ Columnas requeridas presentes
- âœ“ Tipos de datos correctos
- âœ“ Sanidad de datos (sumas coinciden)
- âœ“ Registros cargados = registros esperados
- âœ“ Timestamps vÃ¡lidos

## EjecuciÃ³n del Job:

```bash
# Desde Pentaho Spoon (GUI)
File â†’ Open â†’ j_daily_kpi.kjb â†’ Run

# O desde la lÃ­nea de comandos
./pdi/sh/kitchen.sh -file=/path/to/j_daily_kpi.kjb
```
