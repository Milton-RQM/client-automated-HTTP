# Pipeline de IngestiÃ³n HTTP, Procesamiento de KPIs y ETL

## ğŸ“‹ Tabla de contenidos

1. [DescripciÃ³n general](#descripciÃ³n-general)
2. [Requisitos del proyecto](#requisitos-del-proyecto)
3. [InstalaciÃ³n y configuraciÃ³n](#instalaciÃ³n-y-configuraciÃ³n)
4. [Estructura del proyecto](#estructura-del-proyecto)
5. [CÃ³mo ejecutar el pipeline](#cÃ³mo-ejecutar-el-pipeline)
6. [MÃ³dulos principales](#mÃ³dulos-principales)
7. [Flujo de datos completo](#flujo-de-datos-completo)
8. [Troubleshooting](#troubleshooting)
9. [TecnologÃ­as utilizadas](#tecnologÃ­as-utilizadas)

---

## ğŸ“– DescripciÃ³n general

Este proyecto implementa un **pipeline de datos end-to-end** que:

1. **Simula ingestiÃ³n HTTP** desde APIs (httpbin.org)
2. **Genera logs sintÃ©ticos** con patrones realistas de trÃ¡fico
3. **Procesa datos** y calcula KPIs diarios por endpoint
4. **Carga datos** en base de datos usando ETL (Pentaho)
5. **Genera reportes** HTML con visualizaciones

### ğŸ¯ Objetivos

- Consumir endpoints HTTP con autenticaciÃ³n, cookies, redirecciones, etc.
---

## ğŸ“‹ Requisitos del proyecto

### Requisitos de negocio

**Tareas de IngestiÃ³n HTTP:**
- âœ… AutenticaciÃ³n bÃ¡sica (usuario_test / clave123)
- âœ… Manejo de cookies y sesiones
- âœ… SimulaciÃ³n de restricciones (403)
- âœ… ExtracciÃ³n de datos en JSON, XML, HTML
- âœ… SimulaciÃ³n de envÃ­o de formularios
- âœ… Manejo de redirecciones

**Procesamiento de datos:**
- âœ… GeneraciÃ³n de 500+ logs sintÃ©ticos
- âœ… CÃ¡lculo de KPIs diarios (requests, Ã©xitos, errores, latencia, percentiles)
- âœ… NormalizaciÃ³n de endpoints

**Reportes:**
- âœ… HTML con tablas y grÃ¡ficos
- âœ… MÃ©tricas globales por endpoint
- âœ… Alertas de rendimiento

### Requisitos tÃ©cnicos

| Requerimiento | VersiÃ³n |
|--------------|---------|
| Python | 3.8+ |
| requests | 2.31.0+ |
| faker | 20.0.0+ |
| beautifulsoup4 | 4.12.0+ |
| lxml | 4.9.0+ |
| pandas | 2.0.0+ |
| numpy | 1.24.0+ |
| matplotlib | 3.7.0+ |

**Opcional (para ETL):**
- Pentaho Data Integration 9.0+
- SQLite 3.0+

---

## âš™ï¸ InstalaciÃ³n y configuraciÃ³n

### 1. Clonar o descargar el proyecto

```bash
# Si usas git
git clone <URL_DEL_REPO>
cd client-automated-HTTP

# Si descargaste un ZIP, descomprimelo y abre la carpeta
cd client-automated-HTTP
```

### 2. Crear un ambiente virtual (recomendado)

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Linux / macOS
python3 -m venv venv
source venv/bin/activate
```

### 3. Instalar dependencias

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### 4. Validar instalaciÃ³n

```bash
python setup_and_validate.py
```

**Salida esperada:**
```
âœ“ Python version >= 3.8
âœ“ All required packages installed
âœ“ Directory structure OK
âœ“ Main files present
âœ“ requirements.txt found

âœ“ El proyecto estÃ¡ listo para ejecutar.
```

### 5. (Opcional) Configurar Pentaho

Si deseas usar el mÃ³dulo de ETL con Pentaho:

1. Descarga Pentaho Data Integration (PDI) desde [pentaho.com](https://www.pentaho.com)
2. Extrae en `04_etl_pentaho/`
3. Los archivos `.ktr` y `.kjb` ya estÃ¡n en el proyecto

---

## ğŸ“ Estructura del proyecto

```
client-automated-HTTP/
â”‚
â”œâ”€â”€ 01_ingestion_http/              # MÃ³dulo 1: IngestiÃ³n HTTP
â”‚   â”œâ”€â”€ run_all.py                  # Script principal
â”‚   â”œâ”€â”€ auth/                       # AutenticaciÃ³n bÃ¡sica
â”‚   â”œâ”€â”€ cookies/                    # Cookies y sesiones
â”‚   â”œâ”€â”€ extraction/                 # JSON, XML, HTML
â”‚   â”œâ”€â”€ forms/                      # Formularios POST
â”‚   â”œâ”€â”€ errors/                     # Manejo de 403
â”‚   â”œâ”€â”€ redirects/                  # Redirecciones
â”‚   â””â”€â”€ out/                        # Salidas
â”‚
â”œâ”€â”€ 02_simulation_logs/             # MÃ³dulo 2: Logs sintÃ©ticos
â”‚   â”œâ”€â”€ generar_datos.py            # Generador JSONL
â”‚   â””â”€â”€ out/                        # Logs generados
â”‚
â”œâ”€â”€ 03_kpi_processing/              # MÃ³dulo 3: KPIs
â”‚   â”œâ”€â”€ calcular_kpis.py            # Calculador de KPIs
â”‚   â”œâ”€â”€ README.md                   # DocumentaciÃ³n
â”‚   â””â”€â”€ out/                        # KPIs (CSV)
â”‚
â”œâ”€â”€ 04_etl_pentaho/                 # MÃ³dulo 4: ETL
â”‚   â”œâ”€â”€ t_load_kpi.ktr              # TransformaciÃ³n
â”‚   â”œâ”€â”€ j_daily_kpi.kjb             # Job
â”‚   â”œâ”€â”€ db/                         # Base de datos
â”‚   â””â”€â”€ logs/                       # Logs
â”‚
â”œâ”€â”€ 05_reporting/                   # MÃ³dulo 5: Reportes
â”‚   â”œâ”€â”€ generar_reporte.py          # Generador HTML
â”‚   â””â”€â”€ out/                        # Reportes
â”‚
â”œâ”€â”€ setup_and_validate.py           # ValidaciÃ³n del ambiente
â”œâ”€â”€ requirements.txt                # Dependencias
â””â”€â”€ README.md                       # Este archivo
```

---

## ğŸš€ CÃ³mo ejecutar el pipeline

### EjecuciÃ³n completa (paso a paso)

```bash
# 1. Validar que todo estÃ¡ instalado
python setup_and_validate.py

# 2. Generar datos simulados
python 02_simulation_logs/generar_datos.py \
  --n_registros 500 \
  --seed 42

# 3. Calcular KPIs
python 03_kpi_processing/calcular_kpis.py \
  --input 02_simulation_logs/out/http_logs.jsonl \
  --output 03_kpi_processing/out/kpi_por_endpoint_dia.csv

# 4. Generar reporte HTML
python 05_reporting/generar_reporte.py \
  --input 03_kpi_processing/out/kpi_por_endpoint_dia.csv \
  --output 05_reporting/out/report/kpi_diario.html
```

### EjecuciÃ³n con valores por defecto

```bash
# Generar datos (500 registros, seed 42)
python 02_simulation_logs/generar_datos.py

# Procesar KPIs
python 03_kpi_processing/calcular_kpis.py

# Generar reporte
python 05_reporting/generar_reporte.py
```

---

## ğŸ“Š MÃ³dulos principales

### MÃ³dulo 02: GeneraciÃ³n de logs

Genera archivo JSONL con registros sintÃ©ticos de trÃ¡fico HTTP.

```bash
python 02_simulation_logs/generar_datos.py \
  --n_registros 1000 \
  --seed 42
```

**ParÃ¡metros:**
- `--n_registros`: NÃºmero de registros (default: 500)
- `--seed`: Semilla para reproducibilidad (default: 42)
- `--salida`: Ruta de salida (default: out/http_logs.jsonl)

---

### MÃ³dulo 03: Procesamiento de KPIs

Calcula indicadores de rendimiento diarios por endpoint.

```bash
python 03_kpi_processing/calcular_kpis.py \
  --input 02_simulation_logs/out/http_logs.jsonl \
  --output 03_kpi_processing/out/kpi_por_endpoint_dia.csv
```

**MÃ©tricas:**
- `requests_total`: Total de solicitudes
- `success_2xx`: Solicitudes exitosas (200-299)
- `client_4xx`: Errores del cliente (400-499)
- `server_5xx`: Errores del servidor (500-599)
- `parse_errors`: Registros con parse_result != "ok"
- `avg_elapsed_ms`: Tiempo promedio de respuesta
- `p90_elapsed_ms`: Percentil 90 de tiempo de respuesta

---

### MÃ³dulo 05: Reportes

Genera reporte HTML interactivo con tablas y grÃ¡ficos.

```bash
python 05_reporting/generar_reporte.py \
  --input 03_kpi_processing/out/kpi_por_endpoint_dia.csv \
  --output 05_reporting/out/report/kpi_diario.html \
  --umbral_p90 300
```

**Ver el reporte:**
```bash
# Windows
start 05_reporting/out/report/kpi_diario.html

# Linux
xdg-open 05_reporting/out/report/kpi_diario.html

# macOS
open 05_reporting/out/report/kpi_diario.html
```

---

## ğŸ”„ Flujo de datos completo

```mermaid
graph TD
    A["ğŸŒ IngestiÃ³n HTTP<br/>01_ingestion_http"]
    B["ğŸ“‹ SimulaciÃ³n de Logs<br/>02_simulation_logs<br/>generar_datos.py"]
    C["ğŸ“Š CÃ¡lculo de KPIs<br/>03_kpi_processing<br/>calcular_kpis.py"]
    D["ğŸ”„ ETL - Pentaho<br/>04_etl_pentaho"]
    E["ğŸ“ˆ Reportes<br/>05_reporting"]
    
    F["ğŸ“„ http_logs.jsonl"]
    G["ğŸ“Š kpi_por_endpoint_dia.csv"]
    H["ğŸ—„ï¸ SQLite DB<br/>stg & fct tables"]
    I["ğŸŒ kpi_diario.html"]
    
    A -->|httpbin.org| B
    B --> F
    F -->|Lee| C
    C --> G
    G -->|CSV Input| D
    D -->|Carga| H
    G -->|CSV Input| E
    H -->|AnÃ¡lisis| E
    E --> I
    
    style A fill:#e1f5ff
    style B fill:#f3e5f5
    style C fill:#e8f5e9
    style D fill:#fff3e0
    style E fill:#fce4ec
```

### Detalle: ETL con Pentaho (MÃ³dulo 04)

La transformaciÃ³n `t_load_kpi.ktr` ejecuta:

1. **CSV Input**: Lee `kpi_por_endpoint_dia.csv`
2. **Type Casting**: Convierte tipos (fecha, int, float)
3. **Filter Rows**: Valida integridad:
   - `requests_total > 0`
   - `p90_elapsed_ms >= avg_elapsed_ms`
   - `success_2xx + client_4xx + server_5xx <= requests_total`
4. **Table Output (Staging)**: Inserta en `stg_kpi_endpoint_dia`
5. **Table Output (Fact)**: Inserta en `fct_kpi_endpoint_dia`
6. **Audit Log**: Registra en `audit_etl_log`

El job `j_daily_kpi.kjb` orquesta la transformaciÃ³n y verifica:
- âœ“ NÃºmero de registros cargados
- âœ“ Existencia de tablas
- âœ“ Integridad de datos
- âœ“ Registra logs de ejecuciÃ³n

**Ver diagrama completo:** [FLUJO_ETL.md](04_etl_pentaho/FLUJO_ETL.md)

### Base de datos SQLite

Tres tablas principales:

```sql
-- Staging: copia directa del CSV
stg_kpi_endpoint_dia (
  date_utc, endpoint_base, requests_total, 
  success_2xx, client_4xx, server_5xx, 
  parse_errors, avg_elapsed_ms, p90_elapsed_ms
)

-- Fact Table: para anÃ¡lisis
fct_kpi_endpoint_dia  -- idÃ©ntica a STG

-- AuditorÃ­a: registro de cada carga
audit_etl_log (
  id, job_name, execution_date, records_loaded,
  records_expected, status, error_message
)
```

**Crear tablas:**
```bash
sqlite3 04_etl_pentaho/db/pipeline.db < 04_etl_pentaho/create_tables.sql
```

---

---

## ğŸš¨ Troubleshooting

### "ModuleNotFoundError: No module named 'pandas'"

```bash
pip install -r requirements.txt
```

### "FileNotFoundError: No existe el input JSONL"

```bash
cd 02_simulation_logs
python generar_datos.py --salida out/http_logs.jsonl
```

### "JSON mal formado en lÃ­nea X"

```bash
# Regenera los datos
python 02_simulation_logs/generar_datos.py --n_registros 100
```

### "No existe el archivo de reporte"

```bash
mkdir -p 05_reporting/out/report
python 05_reporting/generar_reporte.py
```

---

## ğŸ“š TecnologÃ­as utilizadas

| CategorÃ­a | TecnologÃ­a |
|-----------|------------|
| Backend | Python 3.8+ |
| HTTP | requests |
| Parsing | beautifulsoup4, lxml |
| Datos sintÃ©ticos | Faker |
| AnÃ¡lisis | pandas, numpy |
| VisualizaciÃ³n | matplotlib |
| ETL | Pentaho Data Integration (opcional) |
| BD | SQLite (opcional) |

---

## ğŸ“ FAQ

**Â¿Puedo usar esto en producciÃ³n?**  
SÃ­. Los mÃ³dulos 02, 03, 05 estÃ¡n listos. El mÃ³dulo 04 requiere instalaciÃ³n de Pentaho.

**Â¿CÃ³mo cambio el umbral de p90?**  
```bash
python 05_reporting/generar_reporte.py --umbral_p90 500
```

**Â¿QuÃ© significa p90_elapsed_ms?**  
Es el percentil 90 del tiempo de respuesta. El 90% de solicitudes tardÃ³ menos que este valor.

**Â¿CÃ³mo aÃ±ado mÃ¡s endpoints?**  
Edita `02_simulation_logs/generar_datos.py` y modifica la lista `ENDPOINTS`.

---

## ğŸ“„ Licencia

Este proyecto fue desarrollado como parte de una **prueba tÃ©cnica** de Data Engineering.

Derechos de uso:
- âœ… Uso educativo y de demostraciÃ³n
- âœ… ModificaciÃ³n y distribuciÃ³n con atribuciÃ³n
- âœ… Uso en entornos de desarrollo y testing
- âš ï¸ No incluye garantÃ­as de soporte para producciÃ³n

---

## âœ‰ï¸ Contacto

**Desarrollador:** Milton RQM  
**GitHub:** [@Milton-RQM](https://github.com/Milton-RQM)  
**Proyecto:** [client-automated-HTTP](https://github.com/Milton-RQM/client-automated-HTTP)

Para preguntas o sugerencias:
- ğŸ“§ Email: milton.rdqm@gmail.com
- ğŸ’¬ Issues: Abre un issue en el repositorio de GitHub
- ğŸ› Bugs: Reporta en la secciÃ³n de Issues

---

## ğŸ“š Referencias

### DocumentaciÃ³n oficial

- **httpbin.org**: [httpbin.org/docs](https://httpbin.org/docs)
- **Python Requests**: [docs.python-requests.org](https://docs.python-requests.org/)
- **Beautiful Soup**: [bs4.readthedocs.io](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
- **Faker (datos sintÃ©ticos)**: [faker.readthedocs.io](https://faker.readthedocs.io/)
- **Pandas**: [pandas.pydata.org](https://pandas.pydata.org/)
- **NumPy**: [numpy.org](https://numpy.org/)
- **Matplotlib**: [matplotlib.org](https://matplotlib.org/)

### Pentaho Data Integration

- **PDI Documentation**: [help.hitachivantara.com/Pentaho DI](https://help.hitachivantara.com/Documentation/Software/Pentaho/9.0)
- **Spoon User Guide**: [GuÃ­a de usuario de Spoon](https://help.hitachivantara.com/Documentation/Software/Pentaho/9.0/en)
- **InstalaciÃ³n**: [pentaho.com/download](https://www.pentaho.com/download)

### SQLite

- **SQLite Docs**: [sqlite.org/docs.html](https://www.sqlite.org/docs.html)
- **Tutorial SQL**: [w3schools.com/sql](https://www.w3schools.com/sql/)
- **Herramientas GUI**: [sqlitebrowser.org](https://sqlitebrowser.org/)

### Conceptos de Data Engineering

- **ETL Concepts**: [en.wikipedia.org/wiki/Extract,_transform,_load](https://en.wikipedia.org/wiki/Extract,_transform,_load)
- **KPIs**: [en.wikipedia.org/wiki/Key_performance_indicator](https://en.wikipedia.org/wiki/Key_performance_indicator)
- **Percentiles**: [en.wikipedia.org/wiki/Percentile](https://en.wikipedia.org/wiki/Percentile)
- **Data Normalization**: [en.wikipedia.org/wiki/Database_normalization](https://en.wikipedia.org/wiki/Database_normalization)

### Herramientas Ãºtiles

- **VS Code**: [code.visualstudio.com](https://code.visualstudio.com)
- **SQLite Browser**: [sqlitebrowser.org](https://sqlitebrowser.org/)
- **Postman (testing HTTP)**: [postman.com](https://www.postman.com/)
- **Git**: [git-scm.com](https://git-scm.com/)

---

## ğŸ“ Aprendizajes clave

Este proyecto demuestra:

1. **IntegraciÃ³n de APIs**: Consumo de endpoints HTTP con requests
2. **Calidad de datos**: ValidaciÃ³n, normalizaciÃ³n y limpieza
3. **IngenierÃ­a ETL**: Pipelines automatizados con Pentaho
4. **AnÃ¡lisis de datos**: KPIs, percentiles, agregaciones
5. **VisualizaciÃ³n**: GrÃ¡ficos y reportes HTML interactivos
6. **AutomatizaciÃ³n**: Scripts reproducibles con parÃ¡metros CLI
7. **Buenas prÃ¡cticas**: DocumentaciÃ³n, errores, validaciÃ³n

---

## âœ¨ Mejoras futuras

- [ ] Agregar autenticaciÃ³n a API de reportes
- [ ] Implementar dashboard en tiempo real con Plotly
- [ ] IntegraciÃ³n con Apache Airflow para orquestaciÃ³n
- [ ] Alertas automÃ¡ticas por email en casos de anomalÃ­as
- [ ] HistÃ³rico de KPIs con consultas de tendencias
- [ ] API REST para consultar KPIs
- [ ] DockerizaciÃ³n del pipeline completo
- [ ] Pruebas unitarias y de integraciÃ³n

---

**Ãšltima actualizaciÃ³n:** 2026-02-06  
**VersiÃ³n:** 1.0.0  
**Estado:** âœ… Listo para ejecuciÃ³n en cualquier equipo con Python 3.8+

â”‚   â”œâ”€ xml/
â”‚   â””â”€ html/
â”‚
â””â”€ run_all.py

